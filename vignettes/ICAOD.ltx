\documentclass[article, nojss]{jss}

%\VignetteIndexEntry{Overview of the ICAOD package}
%\VignetteEngine{R.rsp::tex}
%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{thumbpdf,lmodern}
\usepackage{amsmath}
\usepackage{soul}
%% another package (only for this demo article)
\usepackage{framed}
\usepackage{subfig}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}
%%new commands author
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bnu}{\boldsymbol{\nu}}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bw}{\boldsymbol{w}}
\newcommand{\bbf}{\boldsymbol{f}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bg}{\boldsymbol{g}}
\newcommand{\pos}{\mbox{\textbf{pos}}}
\newcommand{\posi}{\mbox{\textbf{pos}}^{imp}}
\newcommand{\posc}{\mbox{\textbf{pos}}^{col}}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\var}{\mbox{Var}}
\DeclareMathOperator{\argmin}{argmin}
\newcommand{\diag}{\mbox{\textbf{diag}}}


%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Ehsan Masoudi\\University of M\"unster
\And Heinz Holling\\University of M\"unster
\And Weng Kee Wong\\ University of California,\\ Los Angeles
}
\Plainauthor{Ehsan Masoudi, Heinz Holling, Weng Kee Wong}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{ICAOD: An \proglang{R} Package for Finding Optimal Designs for Nonlinear Models Using Imperialist Competitive Algorithm}
\Plaintitle{ICAOD: An R Package for Finding Optimal Designs for Nonlinear Models Using Imperialist Competitive Algorithm }
\Shorttitle{ICAOD \proglang{R} Package}

%% - \Abstract{} almost as usual
\Abstract{
Optimal design ideas  are increasingly used in different disciplines to rein in experimental costs.
Given a statistical model and a design criterion, optimal designs determine the number of experimental points to observe the responses,  the design points and the  number of replications at each design point.  
Currently, there are very few free and effective computing tools for finding different types of optimal designs for a general nonlinear model, especially when the criterion is not differentiable.
We introduce an  \proglang{R} package  \pkg{ICAOD}  to find various types of optimal designs and they include   locally, minimax and Bayesian optimal designs for different   nonlinear models.  Our main computational tool  is a novel metaheuristic algorithm called imperialist competitive algorithm (ICA) and   inspired by  socio-political behavior of humans and colonialism.  We demonstrate its capability and effectiveness using several applications.
%The setup assumes that  the response variable, the predictors, and  a model that links them  are selected, but no data has been collected yet.
The package also includes several theory-based tools to assess  optimality of a generated design  when the criterion is a convex function of the design.
%Finally, we present different examples   to illustrate  the functionality of the \pkg{ICAOD}.
%that non-optimal designs may result in considerable deffiicny of experimental resources in comparison to the optimal designs.
% which is typically  used for visual  verification.
% \pkg{ICAOD}  provides a  formula interface that is used to create the FIM of the model of interest  automatically.
%   All these methods have been  implemented  in the \pkg{ICAOD} package to find optimal designs for nonlinear models.
%It  can also  compute the  efficiency lower bound (ELB) of the generated (approximate) designto reveal an occurrence of  the pre-mature convergence without knowing the optimum. Moreover, \pkg{ICAOD}  offers an ELB-based stopping rule condition that  terminates the algorithm whenever the value of the ELB is larger than a user-specified value, say $0.95$.
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{$c-$optimality, $D-$optimality, design of experiments, evolutionary algorithm,  optimization, population-based algorithm,  \proglang{R}}
\Plainkeywords{c-optimality, D-optimality, design of experiments, evolutionary algorithm,  optimization, population-based algorithm, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  Ehsan Masoudi\\
      Department of Psychology, University of M{\"u}nster\\ Fliednerstr. 21, 48149 Germany\\
E-mail: \email{ehsan.masoudi@uni-muenster.de}\\
\emph{and}\\
Heinz Holling  \\
Department of Psychology, University of M{\"u}nster\\ Fliednerstr. 21, 48149 Germany \\
E-mail: \email{holling@uni-muenster.de} \\
\emph{and}\\
 Weng Kee Wong\\
 Department of Biostatistics \\
   UCLA Fielding School of Public Health\\
 Los Angeles, CA 90095-1772, USA \\
 E-mail: \email{wkwong@ucla.edu}
}

\begin{document}


%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, and \code{} markup throughout the manuscript.
%% - If such markup is in (sub)section titles, a plain text version has to be
%%   added as well.
%% - All software mentioned should be properly \cite-d.
%% - All abbreviations should be introduced.
%% - Unless the expansions of abbreviations are proper names (like "Journal
%%   of Statistical Software" above) they should be in sentence case (like
%%   "generalized linear models" below).

\section{Introduction}
\label{sec:intro}
Optimal designs have been extensively applied in many research studies to reduce the cost of experimentation.   For instance,
\cite{ holling2013introduction} provided examples  in psychology and \cite{dette2010optimal} gave examples in dose-response studies. Further applications of optimal designs in engineering and epidemiology are described in \cite{bergerwong2009},  which also contains applications of optimal design ideas  in other disciplines.
 Given a statistical model and an optimality criterion, optimal designs determine the  optimal number of design points required,  their locations  to observe the responses and the  number of replications required at each location.  The
optimality criterion should accurately reflect the objective of the study to the extent possible and is usually formulated as a scalar function of  the Fisher information matrix (FIM) that measures the worth of the design \citep{lehmann1998theory}.
For example, if the objective of a study is to estimate the model parameters as accurately as possible, $ D$-optimality is often used.  Such an optimal design maximizes the determinant of the FIM and is called $D$-optimal.  When errors are independent and normally distributed, $D$-optimal designs minimize the volume of the confidence ellipsoid of the model parameters by minimizing the generalized variance, i.e.,  the determinant of the variance-covariance matrix \citep{abdelbasit1983}.

For nonlinear models, the FIM  depends on the unknown model parameters to be estimated and so the design criterion cannot be directly optimized.  There are
different approaches   to deal with this parameter dependency: a) {\it locally optimal designs:} These are   found by replacing the  unknown parameters with some initial estimates from a pilot or previous study \citep{chernoff1953}.
Locally optimal  designs usually become inefficient when the initial estimates  are far  from their true unknown values.
b) {\it minimax optimal designs:} They minimize the maximum inefficiency over a user-selected  parameter space \citep{sitter1992}. The optimal designs are conservative in   that they protect the experiment from the worst case scenario that may happen from a poor choice of parameter values over  a user-specified space of plausible values for the unknown parameters.  Finding minimax optimal  designs is  complicated  because it involves solving  multi-level nested optimization problems  and the objective function (minimax criterion) is not differentiable. c) {\it Bayesian optimal designs:}  These optimal designs
  are found by optimizing an  optimality criterion averaged over a user-specified (continuous) prior distribution for the unknown parameters  \citep{chaloner1989, chaloner1995, Atkinson1996}.
Strictly speaking, the latter are not fully Bayesian because they do not involve computing a posterior distribution.
Instead, they borrow the concept of having prior distributions to find robust designs for the frequentists \citep{grasshoff2012optimal, burkner2019optimal}. Accordingly,  they are  sometimes referred to as ``pseudo'' Bayesian  designs \citep{firth1997bayesian}.  In the optimal design literature,  Bayesian optimal designs found under a discrete prior distribution    are  usually referred to as {\it robust } or {\it optimum-on-average} designs  \citep{fedorov2012model}.
For an overview of optimal designs for nonlinear models, see \cite{fedorov2013optimal}.

% Our work here assumes  that  the response variable, the predictors, and  a statistical (nonlinear) model that links them  are selected.
%For example,  are  \cite{ holling2013introduction} for applications in Dyscalculia Research, \cite{dette2010optimal} for applications in dose-response studies and \cite{bergerwong2009} for applications in social and biomedial research.
%In optimal design theory, two  types of designs can be distinguished.
%Simply put,  the first is known as {\it exact design} and it  specifies the exact number of experimental points that are allocated to each design point, whereas the second one is known as approximate or continuous design and it determines the proportion of experimental points that are allocated  to each design point.  Working with approximate designs has an advantage that the optimality or near optimality of a given design may be verified using an equivalence theorem when a convex functional to be optimized.Therefore, in this paper, our main focus is on finding approximate designs.
% For practical purposes, an approximate design is required to be rounded to an exact design.
 %\cite{pukelsheim1992} provide details for various rounding procedures.

There are several software packages to  create and analyze  design of experiment (DoE) for different purposes.  For a review on statistical \proglang{R} packages in design of experiments, see  \url{https://cran.r-project.org/web/views/ExperimentalDesign.html}.  Only a few of them are able to  find different types of optimal designs   to deal with the parameter dependency for various nonlinear models.
To the best of our knowledge, none of the available software packages, commercial or otherwise, provides an option to  find  minimax optimal designs for nonlinear models.
 For example,  the \proglang{R} \citep{R2019} package \pkg{LDOD} \citep{masoudi2013}   finds locally $D-$optimal {\it approximate} designs for a large class of nonlinear models
 and the \pkg{acebayes} \proglang{R} package \citep{overstall2017acebayes} determines a more general class of fully  Bayesian {\it exact} designs  using  the approximate coordinate exchange algorithm \citep{overstall2017bayesian}. Likewise, the recently available
  \pkg{VNM} \proglang{R} package  finds multiple-objective locally optimal designs for a specific model, i.e., the four-parameter Hill model commonly used in dose-response studies \citep{VNM-JSS}.
Among the commercial software, JMP\textsuperscript{\textregistered} \citep{jmp13-design}  can also find Bayesian $D-$optimal exact designs for nonlinear models.

%%%
This paper introduces the \proglang{R} package \pkg{ICAOD} \citep{ICAOD} for finding a variety of  optimal designs for nonlinear models using  a novel metaheuristic algorithm called   {\it imperialist competitive algorithm(ICA)}.
This algorithm  is inspired by  socio-political behavior of humans \citep{ica2007, hosseini2014} and is modified by \cite{masoudi2017} to find optimal designs for nonlinear models.
We believe that this \pkg{ICAOD} package  is the first single self-contained statistical package  that presents  a framework to find   locally, minimax and Bayesian optimal designs for nonlinear models.
Similar to many   popular nature-inspired metaheuristic algorithms, such as particle swarm optimization (PSO) algorithm \citep{Kennedy1995},   ICA  does not have a rigorous  proof of convergence \citep{yang2011metaheuristic}.  When the criterion is a convex function on the set of design measures, equivalence theorems are available  and the \pkg{ICAOD} package includes tools    to confirm optimality of a design.  More generally,  the proximity of any  design to the optimum without knowing the latter can be evaluated in terms of an  efficiency lower bound. In particular, if this bound is unity, this confirms optimality of the design. This feature is  useful to  recognize a case of  pre-mature convergence in optimal design problems.

%Clearly,  in comparison to linear models, finding optimal designs for nonlinear models is complicated, especially for users who are less familiar with advanced statistical and mathematical methods.
 Section~\ref{sec:background} reviews the statistical setup and theory for finding optimal designs for  nonlinear models.
Section~\ref{sec:ICA} describes the imperialist competitive algorithm (ICA) and
 Section~\ref{sec:ICAOD-implementation}  provides  implementation details for  the  \pkg{ICAOD} package.
In  Section~\ref{sec:examples}, we provide two examples to show the functionality of the  \pkg{ICAOD} package;  Section~\ref{sec:logsitc-single} finds locally and minimax $D-$optimal designs for a logistic model with  application in educational testing and
  Section~\ref{sec:sigmoid} presents optimum-on-average and Bayesian $D-$optimal designs for a sigmoid Emax model for dose-response studies.
  The \pkg{ICAOD} package was first written to find locally  $D-$optimal designs, which are arguably most overused in  practice, but it now also finds user-defined optimal designs.  Section~\ref{sec:new-optimality} illustrates how to use this feature to find $c-$optimal designs for a two-parameter  logistic model in dose response studies.
Section~\ref{sec:summary} concludes with a summary.
%Finally,  supplementary material includes a description of a function of  the \pkg{ICAOD} package that finds multiple-objective optimal designs for the four-parameter Hill mode commonly used in dose-response studies  \citep{khinkis2003optimal,holford1981understanding}. We show that using the \pkg{ICAOD} package, it is possible to produced the same results of \pkg{VNM} package  \citep{VNM-JSS}, which is specifically written to solve this type of optimal design problems.


\section{Background and Optimal Designs}
\label{sec:background}
Let $E(Y)=f(\bx,\btheta)$ be the mean of the response $Y$ at the values of the independent variables $\bx$  defined on   a user-selected   {\it design space} $\chi$, and let  $f$ be a known function, apart from the model parameters $\btheta = (\theta_1,..., \theta_p)^T$.  Throughout we assume that there are resources to take $N$ observations for the study and given an optimality criterion, we want to find the best choices for the levels of the independent variables to observe the outcome $Y$.  There are two types of designs: exact and approximate.
% taken at $\bx_1, ..., \bx_N \in \chi$, where $\bx_i$'s are not necessarily distinct.
An {\it exact}  design $\xi_N$ on $\chi$  is  defined by a set of $k$ distinct  levels $\bx_i$,
 \begin{equation}
\label{eq-exact-design}
\xi_N =
\left\{
\begin{array}{cccc}
\bx_1 & \bx_2 & ... & \bx_k\\
n_1/N & n_2/N & ...& n_k/N
\end{array}
\right\},
\end{equation}
 where $\bx_j \in \chi$, $n_j$ is  the  number of replications of $\bx_j$ in the observations sample and  $N = \sum_{j=1}^kn_j$.
 Here, $x_j, j = 1..., k$  are  referred to as {\it support points} or {\it design points} of $\xi_N$.
%By this definition, an exact optimal design problem is equivalent to a mixed-integer (nonlinear) programming.
%However, in practice, the exact optimal design is usually an optimization problem over $\chi$ to find the $N$ non-distinct design points.
Given $N$ and a specific design criterion, an optimal exact design finds the best value of $k$ and the best values of $x_1,\ldots,x_k,n_1,\ldots,n_k$.  Such optimization problems are notoriously difficult and in practice, we find optimal approximate designs instead.  They are probability measure on  $\chi$  are found   independent of the sample size $N$.
%when the denominator in weights ni/n is not restricted to integer values.
An approximate design $\xi$ with $k$ support points has the form
 \begin{equation}
\label{eq-approximate-design}
\xi =
\left\{
\begin{array}{cccc}
\bx_1 & \bx_2 & ... & \bx_k\\
w_1 & w_2 & ...& w_k
\end{array}
\right\},
\end{equation}
where $w_j> 0$ is the proportion of observations that are assigned to  $\bx_j$ and $\sum_{j=1}^{k} w_j = 1$.
They are implemented by  first rounding each value of $Nw_i$ to the nearest integer $Nw_i^*$    subject to $Nw_1^*+\ldots+Nw_k^*=N$ and taking $Nw_i*$ observations at $\bx_i,i=1,\ldots,k$.  Some optimal rounding procedures are available in \citep{pukelsheim1992}.
 %provides details for various rounding procedures.
   When the criterion is convex, there are algorithms for finding many types of optimal approximate designs and theory to   confirm optimality of an approximate design.  When the design is not optimal, a theory-based efficiency lower bound of the design is available to determine its proximity to the optimum, without knowing the optimum.  For these reasons, we focus on  optimal approximate designs found under a convex functional in the rest of the paper.

%Design criteria $\psi$ are usually formulated as a convex function of the FIM because they are asymptotically equal to the variance-covariance matrix of the maximum likelihood estimators.
 A design that minimizes a convex design  criterion $\psi$ over the space of all designs on $\xi$.
% The   minimization is among all  designs on $\Xi = \chi^k \times [0, 1]^k$. 
 This means that  given the model and $\psi$, the optimal number of support points, $k$, the optimal support points $\bx_1,\ldots,\bx_k$ and their corresponding $w_1,\ldots,w_k$ have to be determined.
For example, if estimating model parameters is of interest,  $D-$optimality, defined by the logarithm of the determinant of the  inverse of the FIM, is a convex functional  over the space of all designs on $\chi$ \citep{fedorov2013optimal, silvey1980} and the resulting design is  called $D-$optimal. In what follows, we  focus on the $D-$optimality criterion. The description for  other  optimality criteria is very similar.

Assuming  all observation errors are independent and normally distributed  with means $0$ and a constant variance $\var(Y)$,   the  FIM of a generic $k$-point approximate  design $\xi$ is given by
\begin{equation}
\label{eq:FIM}
M(\xi,\btheta) =  \sum_{i=1}^k w_i I(\boldsymbol{x}_i,\btheta),
\end{equation}
where
\begin{equation*}
I(\boldsymbol{x}_i,\btheta) = \frac{1}{\var(Y_i)}\nabla f(\boldsymbol{x}_i,\btheta)\nabla f(\boldsymbol{x}_i,\btheta)^T,
%~\text{and}~
\end{equation*}
and
$\nabla f(\boldsymbol{x}_i,\btheta)^T=\left(
\frac{\partial f(\boldsymbol{x}_i,\btheta)}{\partial \theta_1},
%\frac{\partial f(\boldsymbol{x}_i,\btheta)}{\partial \theta_2},
\cdots,\frac{\partial f(\boldsymbol{x}_i,\btheta)}{\partial \theta_p}
\right)$.
Here, $\frac{\partial f(\boldsymbol{x}_i,\btheta)}{\partial \theta_j}$
denotes the partial derivative of $f$ with respect to $\theta_j$.
The  FIM  is singular if  $k < p$. To avoid singular designs, i.e., designs with singular Fisher information matrices,  we assume  $k\geq p$.


Clearly, the FIM~\eqref{eq:FIM}  depends on the unknown parameters for nonlinear models.
 Different  approaches have been proposed to deal with this parameter dependency
based on the type of information available for the unknown parameters. For example, let  $\btheta_0$ be an initial guess for $\btheta$ available from a similar study.
 A locally $D-$optimal design $\xi^*_{loc}$  minimizes
\begin{equation}
\label{eq:locally-criterion}
\psi_{loc}(\xi) =   -\log|M(\xi, \btheta_0)|,
\end{equation}
where   $|.|$ denotes  the determinant.  In practice, it is more realistic to assume that the unknown parameters belong to a user-specified parameter space $\Theta$, which  is comprised of all possible values  for $\btheta$. Given $\Theta$, we can find minimax optimal designs that minimize the maximum inefficiency over $\Theta$ and protect the experiment from the worst-case scenario over the parameter space.
A minimax $D-$optimal design $\xi^*_{min}$   is obtained by minimizing
\begin{equation}
\label{eq:minimax-criterion}
\psi_{min}(\xi) =  \max_{\btheta \in \Theta}  -\log|M(\xi, \btheta)|,
\end{equation}
over the space of all designs on $\chi$. The minimax problem~\eqref{eq:minimax-criterion} is a bi-level nested optimization problem with inner and outer optimization problems. Given any arbitrary design, the inner optimization problem is to maximize the $D-$criterion $-\log|M(\xi, \btheta)|$ over $\Theta$ to find the maximum inefficiency  and  the  outer  optimization problem is to  minimize the maximum of the inner problem over  the space of all designs on $\chi$. %Accordingly,  ~\eqref{eq:minimax-criterion} is not differentiable.
Alternatively,  when a prior distribution $\pi_{\Theta}(\btheta)$  is available for the unknown parameters on $\Theta$, Bayesian optimal designs may also be found: a (pseudo) Bayesian  $D-$optimal design $\xi_{bayes}^*$ minimizes
\begin{equation}
\label{eq:bayesian-criterion}
\psi_{bayes}(\xi) = \int_{\btheta \in \Theta}  -\log|M(\xi, \btheta)| \pi_{\Theta}(\btheta) d\btheta.
\end{equation}
When   $\pi_{\Theta}(\btheta)$ is a discrete prior, the obtained designs are sometimes referred to as  {\it optimum-on-average} or {\it robust}  designs.

 One advantage of working with approximate designs is existence of an  equivalence theorem, which can be used to verify the optimality of a given design if the criterion is a convex function on the set of design measures. %Our criteria  are convex in the space of all information matrices and we can obtain the directional derivatives to arrive at an equivalence theorem to check whether a design is optimal among all designs on the given design space $\chi$.
 Each convex optimality criterion gives rise to a different equivalence theorem, but they generally have the same form.
 %For example, suppose that the mean response from a nonlinear regression function has a $p\times 1$ vector of model parameters $\btheta$ and a locally $D-$optimal is sought after.  The equivalence theorem states that
 For example, a design $\xi_{loc}^*$ is locally $D-$optimal  if and only if the following inequality holds for all $\bx \in \chi$,
 \begin{equation}
\label{eq:sensitivity-locally}
c_{loc}(\bx, \xi_{loc}^*) = \tr M^{-1}(\xi_{loc}^*, \btheta_{0})I(\bx, \btheta_{0}) - p \leq 0,
\end{equation}
with equality in~\eqref{eq:sensitivity-locally} at all support points of $\xi_{loc}^*$.
The left hand-side of  inequality~\eqref{eq:sensitivity-locally} is  sometimes called {\it sensitivity function}.
 The equivalence theorem for Bayesian $D-$optimality criterion is very similar \citep{kiefer1959,chaloner1989}: a design $\xi_{bayes}^*$ is a Bayesian $D-$optimal design if and only if the following inequality holds for all $\bx \in \chi$,
\begin{equation}
\label{eq:sensitivity-bayesian}
c_{bayes}(\bx, \xi_{bayes}^*) = \int_{\Theta} \mbox{tr} \{ M^{-1}(\xi_{bayes}^*, \btheta)I(\bx, \btheta)\}\pi(\btheta) d\theta-p \leq 0,
\end{equation}
with equality in~\eqref{eq:sensitivity-bayesian} at all support points of $\xi_{bayes}^*$. However, the  equivalence theorem for  a minimax type criterion  takes on a more complicated form because~\eqref{eq:minimax-criterion} is not differentiable. The equivalence theorem states that a design $\xi^*_{min}$ is minimax $D-$optimal among all the designs on $\chi$ if and only if there exists a probability measure $\mu^*$ on
\begin{equation}
\label{eq:A-set}
A(\xi_{min}^*) = \left\{\bnu \in \Theta \mid -\log|M(\xi_{min}^*, \bnu)| = \max_{\btheta \in \Theta} -\log|M(\xi_{min}^*, \btheta)| \right\},
\end{equation}
such that the following inequality holds for all $\bx \in \chi$,
\begin{equation}
\label{eq:sensitivity-minimax}
c_{min}(\bx, \xi_{min}^*) = \int_{A(\xi_{min}^*)} \tr M^{-1}(\xi_{min}^*, \bnu) I(\bx, \bnu)\mu^* d(\bnu)-p \leq 0,
\end{equation}
 with equality in~\eqref{eq:sensitivity-minimax} at all support points of $\xi_{min}^*$ \citep{wong1992, fedorov1980convex, king2000, berger2000}.
 The set $A(\xi_{min}^*)$ is sometimes called the {\it answering set} of $\xi^*$ and the measure $\mu^*$ is a sub-gradient of the non-differentiable criterion evaluated at $M(\xi_{min}^*,\nu)$.
Understanding the properties of the sub-gradients and how to find them efficiently for the minimax  optimal design problems present a key problem in solving this type of problems.    In particular,  there is no theoretical rule on how to choose the number of points in $A(\xi_{min}^*)$  as support for the measure $\mu^*$ and they would have to be found by trial-and-error. For more details, see \cite{masoudi2017}.
When $\chi$ is one or two dimensional, it is very common to plot the sensitivity function versus $\bx \in \chi$ and  visually inspect whether the graph meets the conditions in the equivalence theorem.  If it does, the generated design is optimal; otherwise it is not optimal.

 It is also possible to measure the efficiency  of two arbitrary designs relative to  each other.
For example, given~\eqref{eq:locally-criterion}, we measure the proximity  of a design $\xi_1$ to
a design $\xi_2$ using its  relative $D-$efficiency defined by
 \begin{equation}
\label{eq:locally-D-efficiency}
 \mbox{eff}_{loc} =\left(\frac{|M(\xi_1, \btheta)|}{|M(\xi_2, \btheta)|}\right)^{1/p} =\exp\left(\frac{\psi_{loc}(\xi_2) - \psi_{loc}(\xi_1) }{p}\right),
\end{equation}
 %begin{equation}
%\label{eq:locally-D-efficiency}
%\mbox{eff}_{loc} = \left(\frac{|M(\xi, \btheta)|}{M(\xi_{loc}^*, \btheta)|}\right)^{1/p}
 %\end{equation}
where $\xi_2$ is usually a locally $D-$optimal design.
The relative $D-$efficiency~\eqref{eq:locally-D-efficiency} may be interpreted in term of sample size; if its value  is $\rho$, then $\xi_1$ requires $1/\rho$ times as many observations to have the same $D-$efficiency as $\xi_2$.
This means that, when $\xi_2$ is an optimal design,  about $(1/\rho-1)100\%$ more number of observations than for the optimal design will be needed to maintain the $D-$efficiency for $\xi_1$.
Similarly, we  can define Bayesian and minimax
$D-$efficiencies by replacing $\psi_{loc}$ with $\psi_{min}$ and $\psi_{bayes}$, respectively.

When the design criterion is a convex functional, we can also use the equivalence theorem to  quantify the proximity of a design to the optimal design without knowing the latter by means of the efficiency lower bound (ELB) defined by
\begin{equation}
\label{eq:ELB}
\mbox{ELB} = \frac{p}{p + \max_{\bx \in \chi}c(\bx, \xi)},
\end{equation}
as a measure of proximity of a design to the optimum, where $c(\bx, \xi)$ is one of the sensitivity functions defined above. According to the equivalence theorem, the value of~\eqref{eq:ELB} is between $0$ and $1$, and it is equal to $1$  when the design is optimal.
\cite{atwood1969optimal} showed that~\eqref{eq:ELB} is the efficiency lower bound  for the $D-$efficiency defined by~\eqref{eq:locally-D-efficiency}.
However, based on the equivalence theorem, we  keep to use~\eqref{eq:ELB} as a measure of proximity  to other types of  optimal designs as well.
%, where values near $1$ denote high proximity of the output designs to the optimum.
%because when ~\eqref{eq:ELB} is not a efficiency lower bound, then it is simply a measure between 0 and 1, where values near 1 deonte the designs with high proximity to the optimum accoriding to the equivalence theorem.

\section{Imperialist Competitive Algorithm for Finding Optimal Designs}
\label{sec:ICA}
The imperialist competitive algorithm (ICA) is an evolutionary algorithm inspired from colonialism and socio-political behavior of humans, where developed countries attempt to take over or colonize less-developed countries  to use their resources and  extend their power \citep{ica2007}. Within the optimization framework,  ICA has a population of solutions called {\it countries}. In optimal design problems, each country is the location of the  support  points and the corresponding weights of a design on the space of all possible designs.
ICA divides the population of countries into some sub-populations called {\it empires}. Each empire contains one {\it imperialist} and some {\it colonies}.  The imperialist is the most powerful country within the empire. Here,  the power of a country is defined to be a function of its cost value, i.e., criterion value. This means that, in a minimization problem, countries with smaller cost values are stronger.
In ICA, there are two types of evolutionary moves: a) evolution within  each empire, and, b) evolution among the empires.
In the earlier, the colonies within each empire start to move or be absorbed  toward their relevant imperialist country  in a process  called {\it assimilation} \citep{lin2013imperialist}.
During this process, a colony may reach a  better position than its imperialist.  In this case, the imperialist loses its rank and the colony becomes the new imperialist.
The assimilation  improves searching around the better current solutions and so enhances the exploitation of the algorithm.

The evolution among the empires is achieved by a process called  {\it imperialists competition}. In this process, the most powerful empires receive more chances to take  possession of the colonies of the weakest empires. %Here,  the total  \textit{power} of an empire is calculated  based on the power of its imperialist and a fraction of the power of its colonies.
The competition step in ICA improves  the exploration of the algorithm in a search for the global optimum.
When an empire does not have any colony, it will be eliminated.
ICA continues until it satisfies the stopping rule conditions.
For more details, see \cite{masoudi2017},  \cite{ica2007} and \cite{hosseini2014}.

To apply ICA for an optimal design problem, the user should first provide an initial guess about the number of support point $k (\geq p)$.
In practice, the user can start by $p$ and  increment its value by one  until  the equivalence theorem confirms the optimality of the current best  design, which is the country with the least cost value.
In optimal design problems, the ELB defined by~\eqref{eq:ELB} can  be used to build a stopping rule condition for ICA. For example, the algorithm can be stopped  when the value of the  ELB of the best current design is larger than, say,  $0.95$. Clearly, finding ELB in each iteration increases the CPU time required by the algorithm  as another  optimization problem has to be solved to find maximum of the sensitivity function over $\chi$. This is especially true for minimax and Bayesian type criteria, because  the sensitivity function for the earlier involves solving a bi-level nested optimization problem  and the latter requires approximating  integrals. Therefore, we prefer to calculate  the ELB  periodically, say, after every $100$  iterations, instead of every iteration to save the CPU time.



\section{Implementation of Optimal Design Problems in  ICAOD}
\label{sec:ICAOD-implementation}
Different functions are available to find optimal designs for nonlinear models in \pkg{ICAOD}: a) \fct{locally}: Finds  locally optimal designs,  b) \fct{minimax}: Finds minimax optimal designs , c) \fct{bayes}: Finds Bayesian optimal designs and d) \fct{robust}: Finds optimum-on-average or robust designs.
Throughout this paper, we refer to them as ``OD  functions''.
\pkg{ICAOD} uses the S3 object oriented  system and  works with  two objects of class \class{minimax} and \class{bayes}.  Each class has its own \code{plot},  \code{print} and \code{update} method. The \code{plot} method is used to plot the sensitivity function and also calculate the ELB for the output design. The \code{update} method is for executing  the algorithm for more number of iterations.
For internal use,   \fct{locally}, \fct{minimax} and \fct{robust} create  an object of class \class{minimax}, while  \fct{bayes} works with  an object of class \class{bayes}. For more details, see \code{?minimax} and \code{?bayes}.
By default, OD functions are defined to determine $D-$optimal designs. In  Section~\ref{sec:new-optimality}, we demonstrate how  to specify user-defined optimality criteria.
In what follows, the OD functions are explained in detail.

\subsection{Locally Optimal Designs}
\label{sec:locally}
The \fct{locally} function  finds locally optimal designs and  its main  arguments are:
    \begin{Code}
locally(formula, predvars, parvars, family = gaussian(), fimfunc = NULL,
        lx, ux, k, iter, ICA.control = list(), sens.control = list(),
        crt_func = NULL, sens_func = NULL,
        inipars)
    \end{Code}
The arguments in the first three lines of codes are common between the OD functions. Table~\ref{tab:overview-shared-arguments} provides an overview of them.
\begin{table}[t!]
\centering
\begin{tabular}{lp{12cm}}
\hline
Argument          &  Description \\ \hline
\code{formula} & A formula  that is the symbolic description of the nonlinear model.  \\
\code{predvars} & A vector of characters that denote the model predictors in \code{formula}.\\
\code{parvars} & A vector of characters that denote the model parameters in \code{formula}.\\
\code{family} &  The distribution of the model response and the link function. It is the same as the one in \fct{glm}.
%This can be a family function, a call to a family function or a character string naming the family, similar to the \fct{glm} function.
The default link function is \fct{gaussian}. \\
\code{fimfunc} & (optional) The Fisher information matrix (\proglang{R} \code{function}). 
Required if  users wish  to pass the FIM directly. It  takes a \code{function} with arguments  \code{x} (a vector of design points), \code{w} (a vector of associated weights) and \code{param} (a vector of model parameters). Only one of the \code{formula} and \code{fimfunc} arguments must be given.\\ \hline
\code{k} & The number of design points $k$. \\
\code{lx} & A vector of the lower bounds for the model predictors (design space $\chi$).\\
\code{ux} & A vector of the upper bounds for the model predictors  (design space $\chi$).\\
\code{x} & (optional) A vector of design points $\bx$. if given, only the optimal weights, \code{w},  are sought after.  Required when the design points are pre-specified.\\
 \hline
\code{ICA.control}  &  A \code{list} of ICA control parameters. By default, it will be created by  \fct{ICA.control}. For more details, see \cite{masoudi2017}.\\
\code{iter} & The maximum number of iterations.\\
 \hline
 \code{sens.control} & Control Parameters of the maximization algorithm, which finds the maximum of the sensitivity function~\eqref{eq:sensitivity-locally},  \eqref{eq:sensitivity-minimax} and \eqref{eq:sensitivity-bayesian} over the design space $\chi$. 
The obtained maximum is used to  calculate the ELB of a design.  By default, it will be created by  \fct{sens.control}.
 \\
  \hline
\code{crt\_func} & (optional) A user-specified criterion  (\proglang{R} \code{function}).\\
  \code{sens\_func} &  (optional) A user-specified sensitivity function (\proglang{R} \code{function}). \\
   \hline
\end{tabular}
\caption{\label{tab:overview-shared-arguments}
Overview of the most important  common arguments of the  OD functions.}
\end{table}
The arguments in the first line are required to construct the FIM of the model; \code{inipars} is equivalent to $\btheta_0$ in \eqref{eq:locally-criterion} and defines the vector of initial estimates for the model parameters.

The  \pkg{ICAOD}  package includes a formula interface to specify the model of interest.  
 For example, assume  the two-parameter logistic model defined by
 \begin{equation}
 \label{eq:logistic-formula}
 f(x, \btheta) = \frac{1}{1 + \exp(-b(x-a))},
\end{equation} 
where $\btheta = (a, b)$ is the vector of model parameters and $x$ is the model predictor. To define~\eqref{eq:logistic-formula}  in  \pkg{ICAOD}, we can set  \code{formula = ~1/(1 + exp(-b * (x-a)))}, \code{predvars = "x"}, \code{parvars = c("a", "b")} and  \code{family = "binomial"} (or \code{family = binomial()}).
Alternatively, one may pass the FIM of~\eqref{eq:logistic-formula} as an \proglang{R} \code{function}  via the argument  \code{fimfunc} directly. In this option, the arguments of the defined function must be  a) \code{x}: is a \code{vector} of  $(\bx_1, ..., \bx_k)$ in~\eqref{eq-approximate-design}, 
b)  \code{w}: is a \code{vector} of  $(w_1, ..., w_k)$ in~\eqref{eq-approximate-design},  and c) \code{param}:  is a  \code{vector} of   $\btheta$ in~\eqref{eq:logistic-formula}. 
The output is the FIM of~\eqref{eq:logistic-formula} evaluated at 
the given \code{x}, \code{w} and \code{param} as a \code{matrix}.
%For more details, see  \code{?minimax}.
%This option is useful when the FIM of the model of interest does not follow the structure in \eqref{eq:FIM}. For more details, see  \code{?minimax}.

%Using these inputs,   \pkg{ICAOD}  creates the FIM of~\eqref{eq:logistic-formula}  as an \proglang{R} \code{function} with arguments \code{x},  \code{w}  and \code{param}. 
%Here,  \code{x} is a \code{vector} of design points, \code{w} is a \code{vector} of associated weights and \code{param} is the vector of model parameters.
%This function should have the same arguments as the internal FIM function explained above and it should return the evaluated FIM as  a \code{matrix}.

%For example, \fct{FIM\_logistic} in \pkg{ICAOD} is a \proglang{C++}  version of the FIM, which is  called within  the \proglang{R} environment using the \pkg{Rcpp} package \citep{rcpp2011, rcpp2013-springer}.

The argument \code{sens.control} is a list of control parameters for   \fct{nloptr} available in the \pkg{nloptr} package  \citep{johnson2014nlopt}. This function is used here to solve  $\max_{\bx \in \chi}c(\bx, \xi)$ for  computing the ELB~\eqref{eq:ELB}. When not given, it will be created automatically   by the function \code{sens.control}.
%Note that, the sensitivity function is usually a multimodal function, especially  when the  design is nearly optimal. 
 We recommend not to change its  default values
as they have been successfully tested for a large number of problems.
%In our  \pkg{ICAOD} package, it is possible to request finding the ELB  periodically, say, after every $100$  iterations, instead of every iteration to save the CPU time.

 The \code{crt\_func} and \code{sens\_func} arguments are used to find a user-defined optimal designs, which are described in 
Section~\ref{sec:new-optimality}. 

\subsection{Minimax Optimal Designs}
\label{sec:minimax}
The  \fct{minimax} function finds minimax optimal designs and  its main  arguments are:
    \begin{Code}
minimax(formula, predvars, parvars, family = gaussian(), fimfunc = NULL,
        lx, ux, k, iter, ICA.control = list(), sens.control = list(),
        crt_func = NULL, sens_func = NULL,
        lp, up, n.grid = 0,
        sens.minimax.control = list(), crt.minimax.control = list())
    \end{Code}
The first three lines of codes are similar to the ones in \fct{locally} and the  rest of the arguments are used  to evaluate the minimax criterion~\eqref{eq:minimax-criterion} and its sensitivity function~\eqref{eq:sensitivity-minimax} at a given design. Table~\ref{tab:overview-criterion-arguments} presents an overview of the  arguments specifically available in \fct{minimax}.

In  \pkg{ICAOD}, the parameter  space $\Theta$ are  either  continuous or discrete. Note that, the lower bound and upper bound of $\Theta$  are specified via the arguments  \code{lp} and \code{up}, respectively. When $\Theta$ is continuous,  \pkg{ICAOD}  uses   \fct{nloptr}  to solve the inner maximization problem  in \eqref{eq:minimax-criterion} over $\Theta$ at a given design.
The default optimization algorithm from \fct{nloptr} is
the DIRECT-L algorithm, which is  a deterministic search algorithm based on the systematic division of the search domain into smaller and smaller hyperrectangles \citep{directL2001}.
For our applications, the most influential tuning parameter of \fct{nloptr}  is  the maximum number of function evaluations denoted by \code{maxeval} (its default value  is $1000$) via the  \code{crt.minimax.control} argument. 
%The default value of  \code{maxeval} is  $1000$ and its value should  be increased for larger $\Theta$ via the argument \code{crt.minimax.control}, which is the list of control parameters 
%The argument  \code{crt.minimax.control}  is a list of control parameters, which includes the control parameters of \fct{nloptr}. By default, this list will be create by \fct{crt.minimax.control}.
The parameter space may also be discretized. In this option,  the total number of grid points is equal to \verb|n.grid^p|. When specified, ICA  evaluates the criterion  at these grid points
to  solve the maximization problem over $\Theta$.
\begin{table}[t!]
\centering
\begin{tabular}{llp{7.5cm}}
\hline
Argument          & function &  Description \\ \hline

%\code{inipars}	& \fct{locally}&
%A vector of the initial estimates $\btheta_0$ for the  model parameters $\btheta$ in \eqref{eq:locally-criterion}.\\\hline
\code{lp}	& \fct{minimax} &
A vector of lower bounds for  $\btheta$. \\
\code{up}	& &
A vector of upper bounds for $\btheta$. \\
\code{n.grid}&  &  (optional) When have a positive value, the parameters space $\Theta$ will be discretized, where the number of grid points will be equal to \verb|n.grid^p| (defaults to $0$).\\
%\code{standardized}&  & A logical, when \code{TRUE}, the optimality criterion is the maximin  standardized $D-$criterion \eqref{eq:maximin-standard-criterion} and the argument \code{localdes} must be given.  Default is set to \code{FALSE}. \\
%\code{localdes} &  &  A function that takes  \code{param} as an argument  and returns a list that contains  the design points \code{x} and  the weights \code{w} of the locally $D-$optimal designs. \\
\code{crt.minimax.control} &  & A list of control parameters of the function \fct{nloptr}, which is used  to maximize the optimality criterion at a given design  over $\Theta$. By default,  it will  be created by \fct{crt.minimax.control}. \\
\code{sens.minimax.control} &  & A list of control parameters to find the answering set \eqref{eq:A-set}, which is  required to obtain the sensitivity function and calculate the ELB. 
By default, it will  be created by \fct{sens.minimax.control}.
For more details, see  \code{?sens.minimax.control}.\\
\hline
\code{prior}	& \fct{bayes} &
An object of class \class{cprior} that contains the necessary  information about the prior distribution for the unknown parameters $\btheta$. For popular prior distributions, 
it can be created via the \fct{uniform}, \fct{normal}, \fct{skewnormal},  \fct{student} functions.
 For more details, see \code{?bayes}.\\
\code{crt.bayes.control}	& & A list of control parameters to approximate the integrals in \eqref{eq:bayesian-criterion}, using either  the \fct{hcubature} function (an adaptive multidimensional integration method over hypercubes) or the Gaussian quadrature formulas implemented by the \pkg{mvQuad} package. By default, it will be created by \fct{crt.bayes.control}.\\
\code{sens.bayes.control} &  & A list of control parameters required to approximate the integrals in  \eqref{eq:sensitivity-bayesian}.  It is very similar to \fct{crt.bayes.control} and by default will be created by \fct{crt.bayes.control}.\\
\hline
\code{prob}	& \fct{robust} &  A \code{vector} of the probability measure  associated with each vector of initial estimates for the unknown parameters $\btheta$.\\
\code{parset}	&  & A \code{matrix} where each of its row is a   vector of the initial estimates for  $\btheta$.   \\
\hline
\end{tabular}
\caption{\label{tab:overview-criterion-arguments}
Overview of the  arguments that are used to evaluate  minimax, Bayesian and robust (optimum-on-average) optimality criteria at a given design.}
\end{table}
%To obtain the sensitivity function for a minimax criterion, we need to find the elements of the answering set   \eqref{eq:A-set}. Obviously,  the answering set is a subset of all the maxima  over the parameter space. Therefore, it is inevitable to find all the local maxima over $\Theta$.
%To this end, \pkg{ICAOD} uses a simple local search strategy as follows.
%It first divides each parameter interval of $\Theta$ into  \code{n_seg} (defaults to $6$) equidistant segments and selects the endpoints. Then, using the Cartesian product, it creates a set of $p$ dimensional  points over $\Theta$ and starts a local search from each point using the \fct{optim} function (\code{"L-BFGS-B"} method).
%The answering set comprises of the  global maximum and,  subject to a merging tolerance (\code{merge_tol = 0.005}),  the local maxima that are near to it. These parameters can be accesses via  the argument  \code{sens.minimax.control}.
 %Obviously, the verification process involves different optimization problems and  consume  CPU time.
  %For more details, see  \citep{masoudi2017, king2000, king2004}.
\subsection{Bayesian Optimal Designs}
\label{sec:Bayesian}
The  \fct{bayes} function finds Bayesian optimal designs and its main  arguments are:
    \begin{Code}
bayes(formula, predvars, parvars, family = gaussian(), fimfunc = NULL,
      lx, ux, k, iter, ICA.control = list(), sens.control = list(),
      crt_func = NULL, sens_func = NULL,
      prior, crt.bayes.control = list(), sens.bayes.control = list())
        \end{Code}
The first three lines of codes are similar to the ones in \fct{locally} and the rest of the arguments are used  to approximate the integrals in \eqref{eq:bayesian-criterion} and \eqref{eq:sensitivity-bayesian} at a given design.
 Table~\ref{tab:overview-criterion-arguments} presents an overview of the  arguments specifically available in \fct{bayes}.

By default,  \pkg{ICAOD} uses the \fct{hcubature} function
from the \pkg{cubature} package \citep{johnson-cubature, cubature} to approximate the integrals.
 Th function \fct{hcubature}  includes an adaptive  multidimensional integration method over hypercubes known as  hcubature algorithm \citep{berntsen1991, genz1980}. For our applications, the most important tuning parameters of  the hcubature algorithm are the maximum number of  integrand evaluations \texttt{maxEval} (its default value is  \code{50000}) and  a user-specified tolerance  \texttt{tol} (its default value is \code{1e-5}). This algorithm stops either when the integral  error estimate is less than the  integral estimate multiplied by its value or when the  it reaches the  specified maximum number of function evaluations \texttt{maxEval}, whichever happens earlier. When the prior distribution is less diffuse, it is sometimes more efficient to reduce  the value of   \texttt{maxEval} to increase the speed of the hcubature  algorithm.% because the integral error estimates  in the hcubature algorithms are  conservative \citep{masoudi2019}.
The control parameters of the \fct{hcubature} function can be regulated via the argument \code{crt.bayes.control}.

Alternatively,   \pkg{ICAOD} also offers  the  Gauss-Legendre  and  the Gauss-Hermite formulas to approximate the integrals.
% for uniform and  normal prior distributions, respectively. 
These methods are implemented in ICA using the \pkg{mvQuad}  package \citep{mvQuad} and can be requested via the argument \code{crt.bayes.control}. For more details, see \fct{?mvQuad::createNIGrid}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%An object of \class{minimax} is comprised of three sub-lists that are briefly explained below.
%\begin{itemize}
%  \setlength\itemsep{-.1em}
%\item \code{arg}: a list of design and algorithm parameters required by \fct{iter} to run the ICA algorithm; or required by the other \pkg{ICAOD} generic functions.
%\item \code{evol}: a list that stores the best design information (the most powerful imperialist or country),  including its criterion value  in each iteration. The output design is stored in the last component of the list.
%\item \code{empires}: a list of the empires (all countries and corresponding criterion values) of the last iteration.
%\item \code{alg}: a list that contains the number of function evaluations \code{fneval}, number of successful  local search \code{nlocal}, the number of   successful revolutions \code{nrevol}, the number of  successful movements toward the imperialist in the assimilation step \code{nimprove} and a convergence message \code{convergence} that says how the algorithm was stopped.
%\end{itemize}
%An object of \class{bayes} is very similar to an object of class \class{minimax} and its description is omitted here due to space consideration. We refer the interested reader to \code{?bayes}.
%The \pkg{ICAOD} also provides \fct{plot} and \fct{print} methods.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Robust or Optimum-On-Average Designs}
\label{sec:optimum-on-average}
The  \fct{robust} function finds optimum-on-average or robust designs and its main arguments are:
    \begin{Code}
robust(formula, predvars, parvars, family = gaussian(), fimfunc = NULL,
       lx, ux, k, iter, ICA.control = list(), sens.control = list(),
       crt_func = NULL, sens_func = NULL,
       prob, parset)
    \end{Code}
The first three lines of codes are similar to the ones in \fct{locally} and the rest of the arguments are used  to evaluate the optimum-on-average criterion at a given design.  Table~\ref{tab:overview-criterion-arguments} presents an overview of the  arguments specifically available in \fct{robust}.


%To find the optimal design, the object of class
%\class{minimax} or \class{bayes} is passed to the generic \fct{update} function to execute ICA. The \fct{plot} function verifies the optimality of the output design by calculating the ELB and  plotting the  sensitivity function if the  given model has one or two predictors.
%Different user-friendly functions are also available  to verify the optimality of a given design  by plotting the  sensitivity function for models with one or two predictors and calculating the ELB.
%Their names start with the prefix \code{sens} and their argument are nearly as same as their relative optimal design functions.  For more details, see \code{?senslocally}, \code{?sensminimax}, \code{?sensbayes} and \code{?sensrobust}.
\section{ Examples}
\label{sec:examples}
In this section, we provide two examples to show the functionality of the  \pkg{ICAOD} package to determine optimal designs. In the first example, we find locally and minimax $D-$optimal designs for a logistic model with applications in educational testing. In the second example, we specify Bayesian and robust optimal designs for the sigmoid Emax model with applications in dose-response studies.
\subsection{ Logistic Model with A Single Predictor}
\label{sec:logsitc-single}
The logistic model is very popular for modeling binary outcomes. For example, consider  an educational research that studies the effect of hours of practice on the mastery of a mathematical task. Let  $Y$ be a binary response variable that  takes the value $1$ if a subject  has mastered the  task and $0$ otherwise. The logistic model is defined by
 \begin{equation}
 \label{eq:logistic-single}
f(x, \btheta) =  P(Y=1) = \frac{\exp(\beta_0 + \beta_1 x)}{1 + \exp(\beta_0 + \beta_1  x)},
 \end{equation}
 where $x$ is the hours of practice and $\btheta = (\beta_0, \beta_1)^T$.   Assume that  for each subject  up to six  hours of practice are possible, i.e., $x \in \chi = [0, 6]$. If  the purpose of the study is to estimate the model parameters accurately, an appropriate criterion is the  $D-$optimality.
The design questions here are a) what is the best number of levels of $x$ to  apply in the study, b) what are these levels  and c) how many subjects  should be  assigned to each level? For example, a researcher may choose a uniform design that  includes an equal number of subjects who have practiced for $0, 1, 2, 3, 4, 5, 6$ hours. We denote this design by
 \begin{equation}
\label{eq-uniform-design}
\xi_{uni} =
\left\{
\begin{array}{ccccccc}
0 & 1 & 2 & 3 & 4 & 5 & 6 \\
1/7& 1/7 & 1/7& 1/7 & 1/7 & 1/7 & 1/7
\end{array}
\right\}.
\end{equation}
%When the purpose of the study is simultaneous estimation of the model parameters, finding  $D-$optimal designs is  sought after.
The FIM of  model~\eqref{eq:logistic-single} depends on the unknown parameters through $\frac{\partial f(\boldsymbol{x},\btheta)}{\partial \beta_j}, j = 0, 1$.
Following \cite{bergerwong2005},  let $\btheta_0 = (-4, 1.3333)^T$ be the best initial guess for $\btheta$ available from, say, a similar study.   In \pkg{ICAOD}, the  locally $D-$optimal design is found by
\begin{CodeChunk}
\begin{CodeInput}
R> library("ICAOD")
R> log1 <- locally(formula = ~exp(b0 + b1 * x)/(1 + exp(b0 + b1 * x)),
+                 predvars = "x", parvars = c("b0", "b1"),
+                 family = "binomial", lx = 0, ux = 6, iter = 40, k = 2,
+                 inipars = c(-4, 1.3333), ICA.control = list(rseed = 1))
R> print(log1)
\end{CodeInput}
\begin{CodeOutput}
***********************************************************************
ICA iter: 40
 Points1 Points2
 1.84249 4.15765
 Weights1 Weights2
  0.500   0.500
Criterion value:  3.568679
Convergence: Maximum_Iteration
CPU time: 3.159  seconds!
***********************************************************************
\end{CodeOutput}
\end{CodeChunk}
Throughout this paper, the \code{rseed} argument is used to guarantee the reproducibility of the results.
The algorithm stopped at iteration number $40$ because it reached  the  maximum number of iterations (\code{iter = 40}).
Here, the design provided by the output assigns equal weights to $x_1 =  1.84249$ and $4.15765$. This mean that, half of the subjects should be assigned to  practice nearly less than 2 hours and the other half should   practice a little bit more than 4 hours.
The $D-$criterion ~\eqref{eq:locally-criterion}  evaluated at  this design  is equal to $3.5686$.
The plot of the sensitivity function of the design provided by the output and the value of the ELB is obtained by
\begin{CodeChunk}
\begin{CodeInput}
R> plot(log1)
\end{CodeInput}
\begin{CodeOutput}
***********************************************************************
Maximum of the sensitivity function is  8.543706e-07
Efficiency lower bound (ELB) is  0.9999996
Verification required 0.269 seconds!
***********************************************************************
\end{CodeOutput}
\end{CodeChunk}
Figure~\ref{fig:sensitivity-logistic-locally} (a) displays the plot of the sensitivity function~\eqref{eq:sensitivity-locally}  of  the design provided by the output on the design space $[0,6]$. Based on the equivalence theorem, this design is optimal because  the sensitivity function is equal or less than zero on $[0,6]$ and (roughly) equal to zero at  $1.84249$ and $4.15765$  (see the red points).  The value of the ELB is nearly $1$, which also indicates the optimality of this design.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t!]
\centering
  \subfloat[][\code{Output from plot(log1)}]{
   \includegraphics[width=.43\textwidth]{log1.pdf}
    }
\subfloat[][\code{Output from plot(log3)}]{
      \includegraphics[width=.43\textwidth]{log3.pdf}
 }
\caption{
Plots of the   sensitivity functions  of the designs generated by  the \fct{locally} function for the logistic model over  $\chi =  [0, 6]$ when $\btheta = \btheta_0 =(-4, 1.3333)^T$.
}
\label{fig:sensitivity-logistic-locally}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

It is  interesting to assess the performance of  the uniform design $\xi_{uni}$ with respect to the locally $D-$optimal design obtained above. Using~\eqref{eq:locally-D-efficiency},  we can calculate the $D-$efficiency of  $\xi_{uni}$ relative to the  locally $D-$optimal design by
\begin{CodeChunk}
\begin{CodeInput}
R> leff(formula = ~exp(b0 + b1 * x)/(1 + exp(b0 + b1 * x)),
+      predvars = "x", parvars = c("b0", "b1"),
+      family = "binomial", inipars = c(-4, 1.3333),
+      x1 = c(0:6), w1 = rep(1/7, 7),
+      x2 = log2$evol[[20]]$x, w2 = log2$evol[[20]]$w)
\end{CodeInput}
\begin{CodeOutput}
[1] 0.7778723
\end{CodeOutput}
\end{CodeChunk}
The value of the relative $D-$efficiency indicates  that $\xi_{uni}$ requires about $100(1/0.777-1)= 29\%$ more number of subjects to have the same $D-$efficiency  as the $D-$optimal design when $\btheta = \btheta_0$.  Therefore, having subjects to practice, say, less than 1 hours or more than 5 hours will not increase the efficiency of the parameter estimates very much. %This example clearly shows how an optimal  design can save the experimental resources and  increase the efficiency of the parameter estimates.



The value of the ELB  may  also be used to construct a stopping rule condition  for  ICA. This  feature  is activated via the  \code{ICA.control} argument in all OD functions similar to what  follows.
\begin{CodeChunk}
\begin{CodeInput}
R> log2 <- locally(formula = ~exp(b0 + b1 * x)/(1 + exp(b0 + b1 * x)),
+                 predvars = "x", parvars = c("b0", "b1"),
+                 family = "binomial", lx = 0, ux = 6, iter = 40, k = 2,
+                 inipars = c(-4, 1.3333),
+                 ICA.control = list(rseed = 1,
+                                    checkfreq = 20,
+                                    stop_rule = "equivalence",
+                                    stoptol = .99))
R> print(log2)
\end{CodeInput}
\begin{CodeOutput}
***********************************************************************
ICA iter: 20
 Points1 Points2
 1.84420 4.15857
 Weights1 Weights2
  0.500   0.500
Criterion value:  3.56868
Convergence: equivalence
CPU time: 2.053  seconds!
***********************************************************************
***********************************************************************
Maximum of the sensitivity function is  8.070843e-05
Efficiency lower bound (ELB) is  0.9999596
Verification required 0.367 seconds!
***********************************************************************
\end{CodeOutput}
\end{CodeChunk}
We set \code{stop_rule = "equivalence"} to activate the stopping rule that is based on the equivalence theorem. In this case,  ICA starts to  calculate the ELB for the best design every \code{checkfreq = 20} iterations  and it  stops whenever the value of the ELB is larger than  \code{stoptol = .99}.  In this example, ICA stopped at the first check run because the value of ELB is $0.999 (> \mbox{\texttt{stoptol}})$.
Note that,  we requested to calculate the ELB    after every $20$ iterations, instead of every iteration, to prevent a significant increase in the CPU time. 
This equivalence-based  stopping rule is  also available in other OD functions. However, we note that,  optimality verification  for  Bayesian or   minimax   type criteria is more complicated and may slow down the ICA.

\pkg{ICAOD} can also handle a situation where the design points are pre-specified, but their optimal associated weights are of interest.
 For example,  assume that the experimental  resources only allow a pre-specified hours of practice, say,   $x_1 = 1$, $x_2 = 2$, $x_3 = 3$ hours. In all OD functions, the design points can be specified  similarly via the argument \code{x} (a vector of design points):
\begin{CodeChunk}
\begin{CodeInput}
R> log3 <- locally(formula = ~exp(b0 + b1 * x)/(1 + exp(b0 + b1 * x)),
+                 predvars = "x", parvars = c("b0", "b1"),
+                 family = "binomial", lx = 0, ux = 6, iter = 40,
+                 x = c(1, 2, 3),
+                 inipars = c(-4, 1.3333),
+                 ICA.control = list(rseed = 1, checkfreq = Inf))

R> print(log3)
\end{CodeInput}
\begin{CodeOutput}
***********************************************************************
ICA iter: 40
 Weights: 0.500 0.000 0.500
Criterion value:  4.187342
Convergence: Maximum_Iteration
CPU time: 3.3  seconds!
***********************************************************************
***********************************************************************
Maximum of the sensitivity function is  2.558775
Efficiency lower bound (ELB) is  0.4387144
Verification required 0.305 seconds!
***********************************************************************
\end{CodeOutput}
\end{CodeChunk}
%Here, the OD functions only return the optimal associated  weights assigned to each element of \code{x}.
The results show that  no weight should be assigned to the subjects with 2 hours of practice. This means that, the responses from subjects with 2 hours of practice  will not increase  the efficiency of estimation very much. Hence, this level may be eliminated  to save more resources.

The value of the ELB and the plot of the sensitivity function in Figure~\ref{fig:sensitivity-logistic-locally} (b) clearly  show that the obtained design is not  globally optimal. This comes as no surprise because the given design points in \code{x} do not belong to the  support of the optimal design when $\btheta = \btheta_0$.
Note that,  \code{checkfreq = Inf} requests a \code{plot} method for the design provided by the output  so that \fct{plot} is not required anymore. For space consideration, we use this option in the rest of this paper.
% In the rest of this paper, for space consideration, we use this option instead of using the \fct{plot} function on the design provided by the output.

Locally optimal designs usually lose their efficiency  when the parameter estimates are far from their true unknown values.
Moreover, in practice, it is more realistic to assume that the parameters belong to a  parameter space, rather than fixing their values at some points. For example, let    $\btheta = (\beta_0, \beta_1)^T$ belongs to $\Theta = [\beta_0^L, \beta_0^U] \times [\beta_1^L, \beta_1^U]$, where $\beta_0^L = -6$,  $\beta_0^U = -2$, $\beta_1^L = .5$ and $\beta_1^U = 2$.
As  a conservative strategy, a  minimax $D-$optimal design   minimizes the maximum inefficiency over $\Theta$.
To find the minimax $D-$optimal design for our design setting, we first set $k = 2$ to find  the minimax $D-$optimal design within the class of two-point designs:
\begin{CodeChunk}
\begin{CodeInput}
R> log4 <- minimax(formula = ~exp(b0 + b1 * x)/(1 + exp(b0 + b1 * x)),
+                 predvars = "x", parvars = c("b0", "b1"),
+                 family = "binomial",
+                 lx = 0, ux = 6, lp = c(-6, .5), up = c(-2, 2),
+                 iter = 200, k = 2,
+                 ICA.control = list(rseed = 1,
+                                    checkfreq = 50,
+                                    stop_rule = "equivalence",
+                                    stoptol = .99),
+                 crt.minimax.control = list(optslist = list(maxeval = 200)))
R> print(log4)
\end{CodeInput}
\begin{CodeOutput}
***********************************************************************
ICA iter: 200
 Points1 Points2
 0.76347 4.89579
 Weights1 Weights2
  0.500   0.500
Criterion value:  7.782754
Convergence: Maximum_Iteration
CPU time: 180.64  seconds!
***********************************************************************
***********************************************************************
Maximum of the sensitivity function is  21.94145
Efficiency lower bound (ELB) is  0.08353714
Verification required 0.623 seconds!
Adjust the value of 'n_seg' in 'sens.minimax.control' for higher speed.
***********************************************************************
\end{CodeOutput}
\end{CodeChunk}
To increase the CPU time, we reduced the value of \code{maxeval} from $1000$ (default value) to $200$.
 Figure~\ref{fig:sensitivity-logistic-minimax} (a) displays the sensitivity plot of the design by provided by the output and it does not verify  the optimality of the two-point design.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t!]
\centering
  \subfloat[][$k = 2$]{
   \includegraphics[width=.43\textwidth]{log4.pdf}
    }
\subfloat[][$k = 3$]{
      \includegraphics[width=.43\textwidth]{log5.pdf}
 }\\
\caption{
Plots of the  sensitivity functions of  the two- and three-point designs generated by the  \fct{minimax} function for the logistic regression model over $ \chi = [0, 6]$ when $\Theta = [-6, -2]\times[0.5, 2]$.  The plot (b) shows the nearly optimality of the three-point design.
}
\label{fig:sensitivity-logistic-minimax}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Therefore, we increment the value of $k$ by one and re-execute the above code:
\begin{CodeChunk}
\begin{CodeInput}
R> log5 <- minimax(formula = ~exp(b0 + b1 * x)/(1 + exp(b0 + b1 * x)),
+                 predvars = "x", parvars = c("b0", "b1"),
+                 family = "binomial",
+                 lx = 0, ux = 6, lp = c(-6, .5), up = c(-2, 2),
+                 iter = 500, k = 3,
+                 ICA.control = list(rseed = 1,
+                                    checkfreq = 50,
+                                    stop_rule = "equivalence",
+                                    stoptol = .99),
+                 crt.minimax.control = list(optslist = list(maxeval = 200)))
R> print(log5)
\end{CodeInput}
\begin{CodeOutput}
***********************************************************************
ICA iter: 200
 Points1 Points2 Points3
 1.06581 2.20682 6.00000
 Weights1 Weights2 Weights3
  0.124   0.383   0.493
Criterion value:  6.736316
Convergence: equivalence
CPU time: 194.165  seconds!
***********************************************************************
***********************************************************************
Maximum of the sensitivity function is  0.005312662
Efficiency lower bound (ELB) is  0.9973507
Verification required 1.516 seconds!
Adjust the value of 'n_seg' in 'sens.minimax.control' for higher speed.
***********************************************************************
\end{CodeOutput}
\end{CodeChunk}
  Figure~\ref{fig:sensitivity-logistic-minimax} (b) displays the plot of the sensitivity function of the three-point generated design and it  indicates its nearly optimality.  %Therefore, the minimax $D-$optimal design  has three points in its support when $\Theta = [-6, -2]\times[0.5, 2] $.
The optimal design  suggests subjects with nearly $1$, $2$ and $6$ hours of practice, where roughly half of the subjects should be  assigned to practice for $6$ hours.


Similar to the locally $D-$optimal design, we can assess the minimax $D-$efficiency of $\xi_{uni}$ with respect to the minimax $D-$optimal design by
  \begin{CodeChunk}
\begin{CodeInput}
R> meff(formula = ~exp(b0 + b1 * x)/(1 + exp(b0 + b1 * x)),
+      predvars = "x", parvars = c("b0", "b1"),
+      family = "binomial",
+      lp = c(-6, .5), up = c(-2, 2),
+      x1 = c(0:6), w1 = rep(1/7, 7),
+      x2 = log5$evol[[200]]$x, w2 = log5$evol[[200]]$w)
\end{CodeInput}
\begin{CodeOutput}
[1] 0.74089
\end{CodeOutput}
\end{CodeChunk}
This value indicates that  $\xi_{uni}$ requires about $100(1/0.74089-1) = 35\%$ more subjects to have the same minimax $D-$efficiency  as the minimax $D-$optimal design  when $\Theta = [-6, -2]\times[0.5, 2]$.


%By default, \pkg{ICAOD}  uses the \fct{nloptr} function to determine the maximum of the criterion function over $\Theta$ at each design point.
%To increase the speed of ICA,   it is also possible to discretize the given parameter space $\Theta$.  Clearly, using this option may decrease the quality of the  output design in s sense that its optimality can not be verified by the equivalence theorem; on the other hand, it also may lead to a nearly minimax optimal design. For more details, see \code{?minimax}.


\subsection{Sigmoid-Emax Model}
\label{sec:sigmoid}
The sigmoid Emax model is commonly used in pharmacokinetics/pharamacodynamics to describe the S-shape dose-response relationship \citep[see, e.g,][]{ Macdougall2006, Thomas2006}.
This model  is defined by
\begin{equation}
\label{eq:sigmoid-Emax}
E(Y) = f(x, \btheta) = \beta_1 + (\beta_2-\beta_1) \frac{x^{\beta_4}}{x^{\beta_4} + \beta_3^{\beta_4}},
\end{equation}
where $x$ is the dose level (in mg), $x \in \chi = (0, x_0]$, $x_0$ is user-selected and  $\btheta = (\beta_1, \beta_2, \beta_3, \beta_4)^T$, $\theta_2>\beta_1$,  $\beta_3>0$.
 All  errors  are assumed to be independent and normally distributed with mean zero and constant variance. Here, $\beta_1$ is the minimum mean response, $\beta_2$ is the maximum mean response, $\beta_3$ is the ED50, i.e., the dose at which $50$ percent of the maximum mean effect is achieved, and $\beta_4$ is the slope parameter.
%The sigmoid Emax model can provide adequate approximations of many families of parametric monotone dose-response models \citep{Thomas2006}.

In dose-response studies, optimal designs  usually  determine how many doses are required to be tested, what are their levels, and how many subjects to allocate to each dose level.
Let  $\chi = (0, 1000]$mg.
Similar to \cite{dragalin2007adaptive} and \cite{wang2014adaptive}, we are interested in efficient estimation of $\btheta$ and the $D-$optimality  is an appropriate design criterion for this purpose.

Using some algebra, it  is straightforward to show that the  FIM of the sigmoid Emax model depends on the unknown parameters $\btheta$. This parameter dependency must be dealt with based on the  type of information available on $\btheta$.
For example, using information from a  pilot study,  one may elicit a uniform prior distribution  for $\btheta$ and search for Bayesian optimal designs.
As an illustrative example, let $\beta_1 \sim U(4, 8)$, $\beta_2 \sim U(11, 15)$, $\beta_3 \sim U(100, 130)$ and $\beta_4 \sim U(5, 9)$,  and all the uniform prior distributions be independent.
For simplicity,  we denote the independent uniform distributions for $\beta_i, i = 1, 2,3, 4$ by $\pi_{\Theta}$,   where $\Theta = [4, 8] \times [11, 15] \times[100,130] \times [5, 9] $ is the parameter space. This prior can be defined in \pkg{ICAOD} by the \fct{uniform}  function as follows.
\begin{CodeChunk}
\begin{CodeInput}
R> prior1 <- uniform(lower = c(4, 11, 100, 5), upper = c(8, 15, 130, 9))
\end{CodeInput}
\end{CodeChunk}
Here, the output is an object  of class \class{cprior}, which can be passed to the argument \code{prior} of  the \fct{bayes} function.

To find the number of support points for the Bayesian $D-$optimal design, we repeated the same incremental process as described in Section~\ref{sec:logsitc-single} for finding minimax optimal design. This process is  excluded here due to space consideration.  The Bayesian $D-$optimal design has $5$ points in its support, which are found by
\begin{CodeChunk}
\begin{CodeInput}
R> sig1 <- bayes(formula = ~b1 + (b2-b1) * x^b4/(x^b4 + b3^b4),
+               predvars = "x",
+               parvars = c("b1", "b2", "b3", "b4"),
+               lx = .001, ux = 1000, k = 5, iter = 400, prior = prior1,
+               ICA.control = list(rseed = 1, checkfreq = Inf))
R> print(sig1)
\end{CodeInput}
\begin{CodeOutput}
***********************************************************************
ICA iter: 400
  Points1   Points2   Points3   Points4   Points5
 0.17040   94.59828  113.69179 138.35282 999.99946
 Weights1  Weights2  Weights3  Weights4  Weights5
   0.243     0.194     0.116     0.203     0.244
Criterion value:  12.72082
Convergence: maxiter
CPU time: 391.99  seconds!
***********************************************************************
***********************************************************************
Maximum of the sensitivity function is  0.0001633976
Efficiency lower bound (ELB) is  0.9999592
Verification required 33.871 seconds!
Adjust the control parameters in 'sens.bayes.control' for higher speed
***********************************************************************
\end{CodeOutput}
\end{CodeChunk}
 Figure~\ref{fig:sensitivity-sigmoid-bayes} (a) presents the plot of the  sensitivity function of the five-point design provided by the output and it verifies its  optimality.
In our example, the Bayesian $D-$optimal design suggests five dose levels, with four of them located below $140$mg and one located at the maximum. Roughly $50\%$ of the observations should be assigned to the lower and upper bound of the dose interval.
Note that, the result can also be obtained in  lesser CPU time if we  adjust the control  parameters of the integral approximations via the argument \code{crt.bayes.control}. For a discussion on these tuning parameters,  see \cite{masoudi2019}.

Using a non-optimal design may  be  inefficient even when its  design points are sampled uniformly from the design space. As an illustrative example, assume a situation where  a researcher decides  to work with an equally-weighted uniform design that has $11$ points located on $0.001, 100, 200, 300, ....,1000$. This design is not  optimal when $\btheta \sim \pi_\Theta$.
The  Bayesian $D-$efficiency  of the uniform design with respect to the obtained Bayesian $D-$optimal design is calculated by
\begin{CodeChunk}
\begin{CodeInput}
R> beff(formula = ~b1 + (b2-b1) * x ^b4/(x^b4 + b3^b4),
+      predvars = "x",
+      parvars = c("b1", "b2", "b3", "b4"),
+      prior = prior1,
+      x1 = c(.001,seq(100, 1000, by = 100)),
+      w1 = rep(1/11, 11),
+      x2 = sig1$evol[[400]]$x, w2 = sig1$evol[[400]]$w)
\end{CodeInput}
\begin{CodeOutput}
[1] 0.3063289
\end{CodeOutput}
\end{CodeChunk}

The non-optimal design may seem to have  fairly chosen,  but its Bayesian $D-$efficiency value suggests that, roughly $226\%$ more observations are needed to maintain the $D-$efficiency for the non-optimal design in comparison to the Bayesian $D-$optimal design when
$\btheta \sim \pi_\Theta$. The \fct{bayes} function  is very  flexible and  can incorporate different   prior distributions. For more details, see \cite{masoudi2019}.

 \pkg{ICAOD} can also  find robust or optimum-on-average designs when the prior distributions  are  discrete. As an illustrative example,  assume $\Theta_0 = \{\btheta_{01}, \btheta_{02} , \btheta_{03} , \btheta_{04} , \btheta_{05}\}$ be a set of five vectors of  initial estimates  for $\btheta = (\beta_1, \beta_2,\beta_3, \beta_4)$, where  $\btheta_{01} = (4, 11, 100, 5)$, $ \btheta_{02} = (5, 12, 110, 6)$, $\btheta_{03} = (6, 13, 120, 7)$, $\btheta_{04} = (8, 15, 130, 9)$ and $\btheta_{05} = (12, 30, 160, 13)$. Let $\pi_{\Theta_0}$ denotes a discrete uniform  prior distribution that assigns the same probability to each vector element of  $\Theta_0$. The six-point optimum-on-average design is given by
 \begin{CodeChunk}
\begin{CodeInput}
R> parset1 <- matrix(c(4, 11, 100, 5,
+                     5, 12, 110, 6,
+                     6, 13, 120, 7,
+                     8, 15, 130, 9,
+                     12, 30, 160, 13),
+                   nrow = 5, byrow = TRUE)
R> sig2 <- robust(formula = ~b1 + (b2-b1) * x ^b4/(x^b4 + b3^b4),
+                predvars = "x",
+                parvars = c("b1", "b2", "b3", "b4"),
+                lx = .001, ux = 1000, k = 6, iter = 400,
+                parset = parset1,
+                prob = rep(1/5, 5),
+                ICA.control = list(rseed = 1, checkfreq = Inf))
R> print(sig2)
\end{CodeInput}
\begin{CodeOutput}
***********************************************************************
ICA iter: 400
  Points1   Points2   Points3   Points4   Points5   Points6
 0.73419   86.42749  112.72244 143.73056 170.57625 999.93217
 Weights1  Weights2  Weights3  Weights4  Weights5  Weights6
   0.200     0.132     0.155     0.186     0.098     0.229
Criterion value:  12.21398
Convergence: Maximum_Iteration
CPU time: 68.501  seconds!
***********************************************************************
***********************************************************************
Maximum of the sensitivity function is  0.0002345949
Efficiency lower bound (ELB) is  0.9999414
Verification required 1.462 seconds!
***********************************************************************
\end{CodeOutput}
\end{CodeChunk}
 Figure~\ref{fig:sensitivity-sigmoid-bayes} (b) displays the  plot of the  sensitivity function of  the design provided by the output  and it verifies the optimality of the six-point design.
 Similar to the optimal design generated by \fct{bayes}, the generated design here allocates most of its support points to the lower half of the dose interval.


 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t!]
\centering
\subfloat[][$\btheta \sim \pi_{\Theta}$]{
   \includegraphics[width=.5\textwidth]{sig1.pdf}
}
 \subfloat[][$\btheta \sim \pi_{\Theta_0}$]{
   \includegraphics[width=.5\textwidth]{sig2.pdf}
}
\caption{
The   plots of sensitivity functions  of  the generated designs  for the sigmoid Emax model  over the design space $ [0.001, 1000]$.
The left panel displays the plot of the sensitivity function of the design generated  by the  function \fct{bayes}   when $\btheta \sim \pi_{\Theta}$. 
The right panel displays the plot of the  sensitivity function of the design generated  by the function \fct{robust}  when $\btheta \sim \pi_{\Theta_0}$.   %Here, $\pi_{\Theta}$ is a continuous and $ \pi_{\Theta_0}$ is a discrete prior distribution.
}
\label{fig:sensitivity-sigmoid-bayes}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Note that, finding the appropriate number of design points $k$ is not a difficult task when the sensitivity plot is available, because the sensitivity plot usually reveals the number of support points even when design is not optimal. For example, if we set $k = 9$,




\section{User-Specified Optimality Criteria}
\label{sec:new-optimality}
\pkg{ICAOD} can also find optimal designs with respect to  user-specified optimality criteria.   In this section, as an illustrative example, we  find $c-$optimal designs for  the two-parameter logistic (2PL) model with applications in dose-response studies.
The 2PL model is commonly used in dose-response studies   to  model the relationship between the dose level of a drug and the probability of  a success, e.g,  the probability that patients are cured. This model is defined by
 \begin{equation}
 \label{eq:logistic-model}
f(x, \btheta) = P(Y=1) =  \frac{1}{1 + \exp(-b(x-a))},
 \end{equation}
where  $x$ is the dose level (predictor), $\btheta = (a, b)^T$,  $b$ is the slope parameter  and $a$ is the dose level at which the response probability is $0.5$ (ED50).  Throughout this paper, we denote the   dose level at which the response probability is equal to $\pi$ by ED$100\pi$.
For the 2PL model, it can be shown that ED$100\pi$  is equal to  $c(\btheta) = a + \gamma b^{-1}$, where $\gamma = \log[\pi/(1-\pi)]$ \citep[see, for example,][]{zhu2001bayesian}. %Clearly,   ED50 results in $c(\btheta) = a$.

Sometimes the purpose of a study is to estimate a function of the unknown parameters, say, ED$100\pi$, rather than estimating all the parameters simultaneously.
For example, in heart defibrillator design problems, estimating   the ED95, or equivalently, estimating  $c(\btheta) = a + \log(0.95/(1-0.95)) b^{-1}$ for the 2PL model  is of interest  \citep{clyde1995optimal}.
In this case, a reasonable optimality criterion is the one that minimizes   the asymptotic variance of the maximum likelihood (ML) estimator  of $c(\btheta)$, which is proportional to
\begin{equation}
\label{eq:c-criterion}
\psi^c(\xi, \btheta) = \nabla^T c(\btheta)M^{-1}(\xi, \btheta)\nabla c(\btheta),
\end{equation}
 where $\nabla c(\btheta)$ is the gradient of $c(\btheta)$ and $M^{-1}(\xi, \btheta)$ is the inverse of the FIM \citep[see, e.g, ][page 4]{silvey1980}.  For the 2PL model, $\nabla c(\btheta) = (1, -\gamma b^{-2})^T$.
%When the purpose is to estimate $c(\btheta)$ efficiently, a reasonable design   is the one that minimizes~\eqref{eq:c-criterion} over the space of all possible designs.
 In the optimal design literature, $\psi^c(\xi, \btheta)$ is referred to as  $c-$optimality criterion and a design that minimizes $\psi^c(\xi, \btheta)$  is called $c-$optimal design.
An equivalence theorem is also available for $c-$optimality: a design  $\xi^*_{c}$  is $c-$optimal among all  the designs on $\chi$ if and only if the following inequality holds for all $x \in \chi$,
\begin{equation}
\label{eq:c-criterion-sensitivity}
c^c(x, \xi^*_{c}) = \tr(B(\btheta) M^{-1}(\xi, \btheta)M(\xi_x, \btheta)M^{-1}(\xi, \btheta)) - \psi^c(\xi, \btheta) \leq 0,
\end{equation}
with equality in~\eqref{eq:c-criterion-sensitivity} for all the support points of $\xi^*_{c}$ \citep[see, e.g,][]{chaloner1989}. Here, $B(\btheta) = \nabla^T c(\btheta)\nabla c(\btheta)$ and $\xi_x$ denotes a degenerate design that puts all its mass on $x$.
% See, for example, \cite{chaloner1989}.

Similar to the $D-$optimality criterion, $c-$optimality also depends on the unknown parameters and different types of optimal designs may be found, depending on how to deal with the unknown parameters.
 As benchmark examples,  in this section, we  find locally and Bayesian $c-$optimal designs for estimating  the ED95 for the 2PL model  when $\chi = [-1, 1]$.
These examples are also available in   \cite{chaloner1989}.
Finding a minimax $c-$optimal or a robust design is very similar and is excluded due to space consideration.
%This example was given in\citep{chaloner1989} who developed a software program named Logit-Design to find  Bayesian $c-$optimal designs using the Nelder-Mead simplex algorithm  \citep{Nelder-Mead1965, zhu2001bayesian}. \textcolor{red}{Prof. Wong, do you remember the programming language they used? Probably Fortran or C?}.

To use \pkg{ICAOD} for finding $c-$optimal designs,  the user should first define the $c-$optimality criterion and its sensitivity function as two separate functions in the  \proglang{R} environment.
Later, these functions will be   passed    to  \fct{bayes}, \fct{minimax}, \fct{locally} and \fct{robust}  via the  \code{crtfunc} and \code{sensfunc} arguments, respectively.
%Note that,  if a Bayesian design is sought after, both of the optimality and sensitivity functions must be vectorized with respect to the model parameters. Otherwise, for  \fct{locally}, \fct{minimax} and \fct{robust} functions no vectorization is required.
For example, given the 2PL model with parameters \code{parvars = c("a", "b")}, the following lines of codes define~\eqref{eq:c-criterion} and \eqref{eq:c-criterion-sensitivity} in the \proglang{R} environment to be used in \fct{locally}, \fct{minimax} and \fct{robust}.
\begin{CodeChunk}
\begin{CodeInput}
R> c_opt <-function(x, w, a, b, fimfunc){
+   gam <- log(.95/(1-.95))
+   M <- fimfunc(x = x, w = w, a = a, b = b)
+   c <- matrix(c(1, -gam * b^(-2)), nrow = 1)
+   B <- t(c) %*% c
+   sum(diag(B %*% solve(M)))
+ }

R> c_sens <- function(xi_x, x, w, a, b, fimfunc){
+   gam <- log(.95/(1-.95))
+   M <- fimfunc(x = x, w = w, a = a, b = b)
+   M_inv <- solve(M)
+   M_x <- fimfunc(x = xi_x, w = 1, a = a, b = b)
+   c <- matrix(c(1, -gam * b^(-2)), nrow = 1)
+   B <- t(c) %*% c
+   sum(diag(B %*% M_inv %*% M_x %*%  M_inv)) - sum(diag(B %*% M_inv))
+ }
\end{CodeInput}
\end{CodeChunk}
The arguments \code{x}, \code{w}  are, respectively,  the vector of design points and their associated weights defined by~\eqref{eq-approximate-design}. \fct{fimfunc} is a function with arguments \code{x}, \code{w}, \code{a} and \code{b} that returns the evaluated FIM  as a \code{matrix} and \code{xi_x} denotes a degenerate design, which has the same length as the number of model  predictors.
The arguments \code{a} and \code{b} are model-specific and denote the parameters of the model that is specified via \code{parvars}.
A convenient feature of \pkg{ICAOD} is that there is no need to  compute the FIM of the model even for a user-specified optimality criterion and  the user can apply  the internally-created FIM within the body of \fct{c\_opt} and  \fct{c\_sens} using  \fct{fimfunc}.
 Note that, both of the \fct{c\_opt} and  \fct{c\_sens}  functions  are not vectorized with respect to  \code{a} and \code{b}. This means that  \fct{fimfunc}  returns only a \code{matrix}, and \fct{c\_opt} and  \fct{c\_sens} return  a value. This is a necessary structure required by the \fct{locally}, \fct{minimax} and \fct{robust} functions.
The following lines of codes provide  the locally $c-$optimal design for estimating the ED95 when $\btheta = (0, 7)$.
\begin{CodeChunk}
\begin{CodeInput}
R> twoPL1 <- locally(formula = ~1/(1 + exp(-b * (x-a))), predvars = "x",
+                   parvars = c("a", "b"), family = "binomial",
+                   lx = -1, ux = 1, inipars = c(0, 7),
+                   iter = 100, k = 2,
+                   crtfunc = c_opt, sensfunc = c_sens,
+                   ICA.control = list(rseed = 1, checkfreq = Inf))
R> twoPL1
\end{CodeInput}
\begin{CodeOutput}
***********************************************************************
ICA iter: 100
 Points1  Points2
 -0.34277 0.34277
 Weights1 Weights2
  0.093    0.907
Criterion value:  0.4028266
Convergence: Maximum_Iteration
CPU time: 5.173  seconds!
***********************************************************************
***********************************************************************
Maximum of the sensitivity function is  2.514716e-08
Efficiency lower bound (ELB) is  1
Verification required 0.504 seconds!
***********************************************************************
\end{CodeOutput}
 \end{CodeChunk}
 The obtained design suggests that nearly $90\%$ of the observations should be assigned to  $0.34277$ and the rest should be allocated to $-0.34277$.
 Figure \ref{fig:c-optimal-2pl} (a) displays the plot of the sensitivity function of the obtained design  and it indicates its optimality.
 Using the given \fct{c\_opt} and  \fct{c\_sens} functions, we can similarly find minimax $c-$optimal or  robust designs. For illustrating example, see  \code{?minimax} and \code{?robust}.%, Section ``Examples''.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t!]
\centering
  \subfloat[][\code{Output from plot(twoPL1)}]{
   \includegraphics[width=.5\textwidth]{twoPL1.pdf}
    }
\subfloat[][\code{Output from plot(twoPL2)}]{
      \includegraphics[width=.5\textwidth]{twoPL2.pdf}
 }
\caption{
Plots of the sensitivity functions of the generated $c-$optimal designs for estimating the ED95 when  $x \in \chi =  [-1, 1]$. The  left panel (a) displays the sensitivity function of the locally  $c-$optimal design when $\btheta = (0, 7)$. The right panel (b) displays the sensitivity function of the  Bayesian $c-$optimal design  when $a\sim U(-0.3, 0.3)$ and $b \sim U(6, 8)$.
}
\label{fig:c-optimal-2pl}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Finding Bayesian $c-$optimal design is  very similar, except that each of~\eqref{eq:c-criterion} and \eqref{eq:c-criterion-sensitivity}	 must be  a vectorized \proglang{R} \code{function} with respect to the model parameters \code{a} and \code{b}:
%with respect to the model parameters \code{a} and \code{b}:
\begin{CodeChunk}
\begin{CodeInput}
R> c_opt_vec <-function(x, w, a, b, fimfunc){
+   gam <- log(.95/(1-.95))
+   M <- fimfunc(x = x, w = w, a = a, b = b)
+   B <- sapply(1:length(M), FUN = function(i)
+     matrix(c(1, -gam * b[i]^(-2)), ncol= 1) %*%
+       matrix(c(1, -gam * b[i]^(-2)), nrow = 1), simplify = FALSE)
+   sapply(1:length(M), FUN = function(i)
+     sum(diag(B[[i]] %*% solve(M[[i]]))))
+ }
R> c_sens_vec <- function(xi_x, x, w, a, b, fimfunc){
+   gam <- log(.95/(1-.95)) # LD .95
+   M <- fimfunc(x = x, w = w, a = a, b = b)
+   M_inv <- lapply(M , FUN = function(FIM) solve(FIM))
+   M_x <- fimfunc(x = xi_x, w = 1, a = a, b = b)
+   B <- sapply(1:length(M), FUN = function(i)
+     matrix(c(1, -gam * b[i]^(-2)), ncol= 1) %*%
+       matrix(c(1, -gam * b[i]^(-2)), nrow = 1), simplify = FALSE)
+   sapply(1:length(M), FUN = function(i)
+     sum(diag(B[[i]] %*% M_inv[[i]] %*% M_x[[i]] %*% M_inv[[i]])) -
+       sum(diag(B[[i]] %*% M_inv[[i]])))
+ }
\end{CodeInput}
\end{CodeChunk}
In the \code{c_opt_vec} and \code{c_sens_vec}  functions, the arguments \code{a} and \code{b} are now vectors of the same (dynamic) length, and \fct{fimfunc} now returns a \code{list} of matrices  with length equal to \code{length(a)}.
Let $a\sim U(-0.3, 0.3)$ and $b \sim U(6, 8)$.
 Given  \code{c_opt_vec} and \code{c_sens_vec}, the Bayesian $c-$optimal design for estimating the ED95  is obtained by
\begin{CodeChunk}
\begin{CodeInput}
R> twoPL2 <- bayes(formula = ~1/(1 + exp(-b * (x-a))), predvars = "x",
+                 parvars = c("a", "b"), family = "binomial",
+                 lx = -1, ux = 1,
+                 prior = uniform(lower = c(-.3, 6), upper  = c(.3, 8)),
+                 iter = 100, k = 3,
+                 crtfunc = c_opt_vec,
+                 sensfunc = c_sens_vec,
+                 ICA.control = list(rseed = 1, ncount = 60, checkfreq = Inf),
+                 sens.bayes.control = list(cubature = list(maxEval = 100)))
R> print(twoPL2)
\end{CodeInput}
\begin{CodeOutput}
***********************************************************************
ICA iter: 100
 Points1  Points2  Points3
 -0.37216 0.02012  0.42577
 Weights1 Weights2 Weights3
  0.026    0.219    0.755
Criterion value:  0.6252608
Convergence: maxiter
CPU time: 117.193  seconds!
***********************************************************************
***********************************************************************
Maximum of the sensitivity function is  0.000523737
Efficiency lower bound (ELB) is  0.9997382
Verification required 2.12 seconds!
Adjust the control parameters in 'sens.bayes.control' for higher speed
***********************************************************************
\end{CodeOutput}
 \end{CodeChunk}
 Figure \ref{fig:c-optimal-2pl} (b) displays the plot of the sensitivity function of the design provided by the output  and it verifies its optimality.
 Similar to the locally  $c-$optimal design, this design puts more than  $97\%$  of its weight on the positive support points.
\section{Summary}
\label{sec:summary}

\pkg{ICAOD} modifies a state-of-the-art metaheuristic algorithm called Imperialist Competitive Algorithm   to find  different types of optimal designs for nonlinear models. We believe this package is more self-contained and has more capability than the few available in the literature. In particular, \pkg{ICAOD} offers different design approaches  for handling the parameter dependency in the information matrix when the model is nonlinear. A useful feature of the \pkg{ICAOD}  package is that it can  create  the Fisher information matrices for a very general class of  nonlinear models automatically and also includes useful theory-based tools   to assess proximity of any design to the   optimal design without knowing the latter.
Using \pkg{ICAOD}, it is also possible  to find optimal designs for a user-specified optimality criterion, including hard-to-find various types of minimax   optimal designs for which the criterion is not differentiable.

Due to space consideration, we presented only a few   examples in this paper to   show the functionality of the package. For additional applications, see \cite{masoudi2017} and \cite{masoudi2019} . The help-documentation manual for the package contains further details and illustrations.  We hope that the generality and simplicity of the \pkg{ICAOD} package will encourage researchers from different disciplines  to explore  optimal design ideas in their work and enable them to implement a more informed design to realize maximum statistical efficiency at minimal cost.


%\pkg{ICAOD} also provides functions to check the optimality of  a user-given design using the equivalence theorem. Their names start with the prefix \code{sens} and their argument are nearly as same as their relative optimal design functions. These functions are useful to verify the optimality of numerical designs presented in literature. For more details, see \code{?senslocally}, \code{?sensminimax}, \code{?sensbayes} and \code{?sensrobust}.

%Similar to other optimization algorithms, ICA has some tuning parameters that should be adjusted for different applications.Our experience is that the most important tuning parameter of the ICA algorithm seems to be the number of countries \code{ncount}, equivalent to the size of population of solutions in other metaheuristic algorithms like PSO. Depending on the type of the optimality criterion, it  also has additional tuning parameters to evaluate the criterion at every given design. %In a Bayesian criterion, when \code{method = "cubature"}, the algorithm uses the \code{hcubature} algorithm for adaptive integral approximation, where its most important tuning parameter is the maximum number of integrand evaluations regulated via \code{maxEval}. When a traditional quadrature method is selected, i.e. \code{method = "quadrature"}, then the parameter \code{levels} from the \code{mvQuad::createNIGrid} function becomes the most important tuning parameter. By default,  it is  equal to the number of grid points for the underlying one-dimensional quadrature rule. Nevertheless, the value of both tuning parameters must be sufficient enough to guarantee accurate approximations of the integral. Obviously, when the model has a large number of parameters, a speed-accuracy  compromise is inevitable.
% and this can be reached by adjusting the value of theses tuning parameters for approximating the optimality criterion and the sensitivity function via the arguments \code{crt.bayes.control} and \code{sens.bayes.control}, respectively.


% For minimax type criteria, when the parameter space is continuous (\code{n.grid = 0}), the key tuning parameter is the maximum number of function evaluations  \code{maxeval}, which is passed to the \code{nloptr} function to optimize the criterion over the continuous parameter space.
 %Here, the value of \code{maxeval} must be large enough so that the optimizer can find the global optimum over the parameter space; otherwise, the algorithm may reach a pre-mature convergence and  the optimality of the generated design is not verified by the equivalence theorem.
 %Obviously, when the user wish to discretize the parameter space,  the number of grid points in each dimension of the parameter space, i.e. \code{n.grid}, becomes the only  tuning parameter for evaluating the minimax criterion. Again, its value must be large enough so that the global maximum is not missed for any given design.


%The tuning parameters for evaluating a minimax type criterion and its sensitivity function can be regulated via the argument  \code{crt.minimax.control} and \code{sens.minimax.control}, respectively.

%Finally, we would like to emphasize that, no matter what  type of optimality criteria is applied, the more accurate information available for the locations of the unknown parameters, the higher will be the efficiency of the obtained design with respect to the true unknown optimal design, i.e. the  design found when the parameters are located at exactly at the true unknown parameters. Assuming a large $\Theta$ in the minimax type criteria or more diffuse prior in the Bayesian type criteria reduces in the efficiency of the obtained design with respect to the true optimal design, and, on the other hand, it increases the number of design points that is sometimes undesirable due to an increase in the  experiment expenses (more number of design points are required to be executed in order to observe their responses).
%may increase the robustness of the obtained design with respect to the misspecification of the parameters or protect us against a more worse scenario, but, on the other hand,
 %Therefore, for real applications,  we encourage the user to provide more accurate information for the unknown parameters as far as possible. This means that, for locally optimal designs more accurate initial estimates, for minimax or standardized maximin optimal designs smaller $\Theta$ and for  Bayesian optimal designs less diffuse prior on $\Theta$ are provided.


%The key tunging parameters are maxeval, maxEval and n.seg
%% -- Optional special unnumbered sections -------------------------------------
\section*{Computational details}
%If necessary or useful, information about certain computational details
%such as version numbers, operating systems, or compilers could be included
%in an unnumbered section. Also, auxiliary packages (say, for visualizations,
%maps, tables, \dots) that are not cited in the main text can be credited here.
The results in this paper were obtained using
\proglang{R}~  3.5.3  with the
\pkg{ICAOD}~ 0.9.9 package. \proglang{R} itself
and all packages used are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at
\url{https://CRAN.R-project.org/}.


\section*{Acknowledgments}
%We are grateful to the editor, associate editor and two reviewers for their timely review and valuable comments.
We would like to thank Dr. Paul-Christian B\"urkner for his  helpful comments when writing the package and this manuscript.
The research of Wong reported in this paper was partially supported by a grant award R01GM107639 from the National Institute of General Medical Sciences of the National Institutes of Health.
The research of Holling and Masoudi  in this paper was partially supported by a grant (HO 1286/6 - 4) of the German Research Foundation (DFG). 
The contents in this paper are solely the responsibility of the authors and do not necessarily represent the official views of the National Institutes of Health.

%% -- Bibliography -------------------------------------------------------------
%% - References need to be provided in a .bib BibTeX database.
%% - All references should be made with \cite, \citet, \citep, \citealp etc.
%%   (and never hard-coded). See the FAQ for details.
%% - JSS-specific markup (\proglang, \pkg, \code) should be used in the .bib.
%% - Titles in the .bib should be in title case.
%% - DOIs should be included where available.

\bibliography{ICAOD}


%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".


%\begin{appendix}
%%%%%%%%%%%%%%%%%


%\end{appendix}

%% -----------------------------------------------------------------------------


\end{document}
